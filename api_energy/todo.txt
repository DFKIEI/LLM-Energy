Local - 

h100-200
10 runs

repeat with microsoft phi models(where equivalent with API)

find some more models(where equivalent API available)

Local - Llama3.1-8b(https://huggingface.co/meta-llama/Llama-3.1-8B), llama guard4 - 12b(https://huggingface.co/meta-llama/Llama-Guard-4-12B) 

API - 

track the amount of inputs, output and total tokens for both local and API models



-----------------------------------------

and figure out the tokenizers used(API)

------------------------------------------

API calls every 30 mins for 1 week(unpaid and paid mistral) block 1 job only
API jobs for mistral paid

------------------

broader overview of the script - datasets and models and process - the experiment protocol (bullet points) carbon tracker - epoch wise tracking rather prompt tracking
 just a short paragraph - quarter page

 system prompt, temperature, hyperparameters

 explanation of code


 ----------------------------

 try multi-gpu

 split model files on different gpus(check with huggingface)

 explore the parameters


 -----------------------

 track ping server for each request over time(another thread)
 track time for each request individually and overall and energy per input token and per output token(100-1, 1000-1 and opposite tokens(input and output))
 different benchmarks
 track time with time and carbontracker both
 carbon tracker num of samples epoch
 locally api not on cluster
 multi gpu
 A100-80, H100, H200, B200


 -----------------

multi gpu - layerwise and tensorwise
bigger models
2 gpus - 4 gpus
api jobs on machine